---
apiVersion: batch/v1
kind: Job
metadata:
  name: fine-tuning-llama
spec:
  template:
    metadata:
      name: fine-tuning-llama
      namespace: llama
    spec:
      hostIPC: true
      containers:
      - name: fine-tuning-llama
        image: vault.habana.ai/gaudi-docker/1.18.0/ubuntu22.04/habanalabs/pytorch-installer-2.4.0:latest
        workingDir: /root
        command:
        - bash
        args:
        - -c
        - 'config/benchmarks.sh'
        env:
        - name: HABANA_VISIBLE_DEVICES
          value: all
        - name: HF_TOKEN
          valueFrom:
            secretKeyRef:
              name: hf-token-1
              key: HF_TOKEN
        - name: OMPI_MCA_btl_vader_single_copy_mechanism
          value: none
        - name: PT_HPU_MAX_COMPOUND_OP_SIZE
          value: "10"
        - name: DEEPSPEED_HPU_ZERO3_SYNC_MARK_STEP_REQUIRED
          value: "1"
        resources:
          # Resources can be changed as needed
          limits:
            habana.ai/gaudi: 2
            memory: 800Gi
            hugepages-2Mi: 95000Mi
          requests:
            habana.ai/gaudi: 2
            memory: 800Gi
            hugepages-2Mi: 95000Mi
        securityContext:
          capabilities:
             add: ["SYS_NICE"]
          privileged: true
          runAsUser: 0
        volumeMounts:
        - name: data
          mountPath: /root
        - name: config
          mountPath: /root/config
      restartPolicy: Never
      volumes:
      - name: config
        configMap:
          name: fine-tuning-llama
          defaultMode: 0500
      - name: data
        #emptyDir: {}
        hostPath:
          path: /scratch-1/llama
          type: Directory
